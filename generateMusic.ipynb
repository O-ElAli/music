{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a6e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved vocabulary...\n",
      "Model loaded successfully.\n",
      "Generating ABC tune...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geome\\AppData\\Local\\Temp\\ipykernel_34224\\846896658.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"best_model.pth\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated ABC Notation ===\n",
      "\n",
      "X:1\n",
      "T:Generated Tune\n",
      "M:4/4\n",
      "L:1/8\n",
      "K:D\n",
      " fAG FED BAB | ded dAF DEF | G3 AFA F2 d | AFD D2 C D2 :| Bd | e3 efe e3 cde | \n",
      "\"^13\" f2 f fdf b3 f2 f | a2 f afd d^cd fed | e2 B dfe dcB ABd | f2 e fef A3 faf | B2 B AGF E3 e2 :|2 \n",
      " aba afb a2 f aba | d'2 b f3 a6 |: g2 f ede b3 b2 b | f2 e f2 a f2 e d2 A | d2 A d3 f2 e d2 f a2 g f2 e e3 e2 f | f2 c f2 a a2 f f2 a g3 f3 f2 e e2 f e2 f e2 d c2 d e3 c3 A2 e c d c B3 c2 G E2 F F4 E3 C a e g8 c3 z2 d d2 e c A6 z2 A | \n",
      " e2 d e2 a c2 a e8 d e4 d e4 | g f3 B4 A4 E4 D4 E8 | D6 F2 | E3 E TF3 E G3 E A6 (E2 G2) F4 ^G4 E4 D2 D4 || B>B | A3 d d2 d6 | d4 dc/B/ c3 A A2 D4 E2 E6 E2 || e3 ^f !>!a3 A .^G3 .A .B4 G4 .A6 B2 | (A6 A2) A6 A6 z2 | \n",
      " d2 B4 (A3 B) B8 B4 A3 G F6 (FG) A6 z4 (b4 B4) | a2 g4 ^f6 g4 (e6 e2) e6 e6 e6 e2 z4 z2 z4 z2 z2 | z6 z6 d6 _e6 e4 f2 z4 z6 z2 fe d6 e4 e6 b4 f2 b2 e4 fe ^d2 e6 f4 e8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "# === Parameters ===\n",
    "SEQ_LENGTH = 75\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 1\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "GENERATE_LENGTH = 800\n",
    "TEMPERATURE = 1.0  # Set between 0.7 and 1.2 for different output styles\n",
    "\n",
    "# === Load or rebuild vocab ===\n",
    "vocab_path = \"vocab.json\"\n",
    "if os.path.exists(vocab_path):\n",
    "    print(\"Loading saved vocabulary...\")\n",
    "    with open(vocab_path) as f:\n",
    "        vocab_data = json.load(f)\n",
    "    char2idx = {k: int(v) for k, v in vocab_data['char2idx'].items()}\n",
    "    idx2char = {int(k): v for k, v in vocab_data['idx2char'].items()}\n",
    "    VocabSize = len(char2idx)\n",
    "else:\n",
    "    print(\"Building vocabulary from dataset...\")\n",
    "    dataset = load_dataset('sander-wood/irishman', split='train')\n",
    "    texts = dataset['abc notation']\n",
    "    vocab = sorted(set(''.join(texts)))\n",
    "    char2idx = {ch: i for i, ch in enumerate(vocab)}\n",
    "    idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "    VocabSize = len(vocab)\n",
    "\n",
    "    with open(vocab_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"char2idx\": char2idx,\n",
    "            \"idx2char\": {str(k): v for k, v in idx2char.items()}\n",
    "        }, f)\n",
    "    print(\"Vocabulary saved to vocab.json.\")\n",
    "\n",
    "# === Define model ===\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(VocabSize, EMBED_DIM)\n",
    "        self.lstm = nn.LSTM(EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, batch_first=True)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM, VocabSize)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = out.reshape(-1, HIDDEN_DIM)\n",
    "        logits = self.fc(out)\n",
    "        return logits, hidden\n",
    "\n",
    "# === Load model ===\n",
    "model = SimpleRNN().to(DEVICE)\n",
    "\n",
    "if not os.path.exists(\"best_model.pth\"):\n",
    "    raise FileNotFoundError(\"Checkpoint 'best_model.pth' not found!\")\n",
    "\n",
    "checkpoint = torch.load(\"best_model.pth\", map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# === Generate ABC header ===\n",
    "M_options = [\"M:6/8\", \"M:4/4\", \"M:3/4\"]\n",
    "L_options = [\"L:1/8\", \"L:1/16\", \"L:1/4\"]\n",
    "K_options = [\"K:D\", \"K:G\", \"K:C\"]\n",
    "\n",
    "start = f\"\"\"X:1\n",
    "T:Generated Tune\n",
    "{random.choice(M_options)}\n",
    "{random.choice(L_options)}\n",
    "{random.choice(K_options)}\n",
    "\"\"\"\n",
    "\n",
    "seq = [char2idx.get(c, 0) for c in start]\n",
    "hidden = None\n",
    "\n",
    "# === Generate sequence ===\n",
    "print(\"Generating ABC tune...\")\n",
    "for i in range(GENERATE_LENGTH):\n",
    "    inp_seq = seq[-SEQ_LENGTH:]\n",
    "    inp = torch.tensor(inp_seq, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "    logits, hidden = model(inp, hidden)\n",
    "\n",
    "    # Reset hidden periodically to prevent drift\n",
    "    if i % 100 == 0:\n",
    "        hidden = None\n",
    "\n",
    "    probs = torch.softmax(logits[-1] / TEMPERATURE, dim=0)\n",
    "    idx = torch.multinomial(probs, 1).item()\n",
    "    seq.append(idx)\n",
    "\n",
    "# === Decode and save ===\n",
    "generated = ''.join(idx2char[i] for i in seq)\n",
    "print(\"\\n=== Generated ABC Notation ===\\n\")\n",
    "print(generated)\n",
    "\n",
    "with open(\"generated_tune.abc\", \"w\") as f:\n",
    "    f.write(generated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0115974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10851e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
